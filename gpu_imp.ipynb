{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws, length, regexp_replace, size, split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def main():\n",
    "    spark = (SparkSession.builder\n",
    "    .appName(\"GPU_FINAL_TEST\")\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\")\n",
    "        .config(\"spark.driver.host\", \"localhost\") # Bu ayarı koruyalım, WSL için önemli\n",
    "        .getOrCreate()\n",
    "    )\n",
    "        \n",
    "    data_path = \"/mnt/c/Users/BerenÜnveren/Desktop/BIL401/data/train.csv\"\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"Id\", IntegerType(), True),\n",
    "        StructField(\"Title\", StringType(), True),\n",
    "        StructField(\"Body\", StringType(), True),\n",
    "        StructField(\"Y\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    df = spark.read.format(\"csv\") \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"quote\", \"\\\"\") \\\n",
    "        .option(\"multiLine\", \"true\") \\\n",
    "        .load(data_path)\n",
    "    \n",
    "    df.printSchema()\n",
    "    df.groupBy(\"Y\").count().show()\n",
    "\n",
    "    df_clean = df.na.drop(subset=[\"Title\", \"Body\", \"Y\"]) \\\n",
    "        .withColumn(\"CleanBody\", regexp_replace(col(\"Body\"), \"<.*?>\", \"\")) \\\n",
    "        .withColumn(\"text\", concat_ws(\" \", col(\"Title\"), col(\"CleanBody\")))\n",
    "\n",
    "    df_featured = df_clean.withColumn(\"title_len\", length(col(\"Title\"))) \\\n",
    "        .withColumn(\"body_len\", length(col(\"CleanBody\"))) \\\n",
    "        .withColumn(\"punct_count\", length(col(\"text\")) - length(regexp_replace(col(\"text\"), \"[?!]\", \"\"))) \\\n",
    "        .withColumn(\"avg_word_len\", length(regexp_replace(col(\"text\"), \" \", \"\")) / (size(split(col(\"text\"), \" \")) + 1e-6))\n",
    "    \n",
    "    label_indexer = StringIndexer(inputCol=\"Y\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "    hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=20000)\n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"text_features\")\n",
    "    \n",
    "    feature_assembler = VectorAssembler(\n",
    "        inputCols=[\"text_features\", \"title_len\", \"body_len\", \"punct_count\", \"avg_word_len\"],\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    (train_data, test_data) = df_featured.randomSplit([0.8, 0.2], seed=42)\n",
    "    train_data.cache()\n",
    "    test_data.cache()\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "    lr_pipeline = Pipeline(stages=[label_indexer, tokenizer, stopwords_remover, hashing_tf, idf, feature_assembler, lr])\n",
    "    lr_model = lr_pipeline.fit(train_data)\n",
    "    lr_predictions = lr_model.transform(test_data)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    lr_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(lr_predictions)\n",
    "    lr_f1 = evaluator.setMetricName(\"f1\").evaluate(lr_predictions)\n",
    "    \n",
    "    print(\"\\nLogistic Regression Evaluation\")\n",
    "    print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {lr_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    lr_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "\n",
    "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "    rf_pipeline = Pipeline(stages=[label_indexer, tokenizer, stopwords_remover, hashing_tf, idf, feature_assembler, rf])\n",
    "    \n",
    "    rf_model = rf_pipeline.fit(train_data)\n",
    "    rf_predictions = rf_model.transform(test_data)\n",
    "    rf_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(rf_predictions)\n",
    "    rf_f1 = evaluator.setMetricName(\"f1\").evaluate(rf_predictions)\n",
    "\n",
    "    print(\"\\nRandom Forest Evaluation\")\n",
    "    print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {rf_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    rf_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession.getActiveSession()\n",
    "        if spark:\n",
    "            spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83c513-5b39-4f43-857e-68d4f52d46d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAPIDS 24.02)",
   "language": "python",
   "name": "rapids-24.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
