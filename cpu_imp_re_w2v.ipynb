{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1f8a7b",
   "metadata": {},
   "source": [
    "1. Lib Imports & UDF Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import traceback\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, length, concat_ws\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, \n",
    "    VectorAssembler, NGram\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "def count_punctuation(text):\n",
    "    if text is None: return 0\n",
    "    return len(re.findall(r'[?!]', text))\n",
    "\n",
    "def avg_word_length(text):\n",
    "    if text is None: return 0.0\n",
    "    words = text.split()\n",
    "    if not words: return 0.0\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    if text is None: return None\n",
    "    return re.sub(re.compile('<.*?>'), '', text)\n",
    "\n",
    "def clean_tags(tags):\n",
    "    if tags is None: return []\n",
    "    return tags.replace('<', ' ').replace('>', ' ').strip().split()\n",
    "\n",
    "count_punct_udf = udf(count_punctuation, IntegerType())\n",
    "avg_word_len_udf = udf(avg_word_length, DoubleType())\n",
    "remove_html_udf = udf(remove_html_tags, StringType())\n",
    "clean_tags_udf = udf(clean_tags, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c8e86",
   "metadata": {},
   "source": [
    "2. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data schema:\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- Y: string (nullable = true)\n",
      "\n",
      "+--------+-----+\n",
      "|       Y|count|\n",
      "+--------+-----+\n",
      "|LQ_CLOSE|15000|\n",
      "|      HQ|15000|\n",
      "| LQ_EDIT|15000|\n",
      "+--------+-----+\n",
      "\n",
      "\n",
      "log reg results:\n",
      "accuracy: 0.6659\n",
      "F1 score: 0.6669\n",
      "conf m:\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0| 1825|\n",
      "|  0.0|       1.0|  785|\n",
      "|  0.0|       2.0|  367|\n",
      "|  1.0|       0.0|  887|\n",
      "|  1.0|       1.0| 1832|\n",
      "|  1.0|       2.0|  261|\n",
      "|  2.0|       0.0|  447|\n",
      "|  2.0|       1.0|  261|\n",
      "|  2.0|       2.0| 2338|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "RF HP optimization:\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"CPU_IMP_RE_W2V\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data_path = \"data/train.csv\"\n",
    "\n",
    "try:\n",
    "    df = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"quote\", \"\\\"\") \\\n",
    "        .option(\"escape\", \"\\\"\") \\\n",
    "        .option(\"multiLine\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(data_path)\n",
    "    \n",
    "    print(\"data schema:\")\n",
    "    df.printSchema()\n",
    "    df.groupBy(\"Y\").count().show()\n",
    "\n",
    "    df_clean = df.na.drop(subset=[\"Title\", \"Body\", \"Tags\", \"Y\"]) \\\n",
    "        .withColumn(\"CleanBody\", remove_html_udf(col(\"Body\"))) \\\n",
    "        .withColumn(\"text\", concat_ws(\" \", col(\"Title\"), col(\"CleanBody\"))) \\\n",
    "        .withColumn(\"tags_list\", clean_tags_udf(col(\"Tags\")))\n",
    "    \n",
    "    df_featured = df_clean.withColumn(\"title_len\", length(col(\"Title\"))) \\\n",
    "        .withColumn(\"body_len\", length(col(\"CleanBody\"))) \\\n",
    "        .withColumn(\"punct_count\", count_punct_udf(col(\"text\"))) \\\n",
    "        .withColumn(\"avg_word_len\", avg_word_len_udf(col(\"text\")))\n",
    "\n",
    "    label_indexer = StringIndexer(inputCol=\"Y\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "    \n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "    ngram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"bigrams\")\n",
    "    \n",
    "    #hashing_tf_text = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_text_features\", numFeatures=20000)\n",
    "    #idf_text = IDF(inputCol=\"raw_text_features\", outputCol=\"text_features\")\n",
    "    \n",
    "    #hashing_tf_bigrams = HashingTF(inputCol=\"bigrams\", outputCol=\"raw_bigrams_features\", numFeatures=20000)\n",
    "    #idf_bigrams = IDF(inputCol=\"raw_bigrams_features\", outputCol=\"bigrams_features\")\n",
    "    \n",
    "    w2v = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"w2v_features\")\n",
    "    \n",
    "    hashing_tf_tags = HashingTF(inputCol=\"tags_list\", outputCol=\"raw_tags_features\", numFeatures=5000)\n",
    "    idf_tags = IDF(inputCol=\"raw_tags_features\", outputCol=\"tags_features\")\n",
    "\n",
    "    feature_assembler = VectorAssembler(\n",
    "        inputCols=[\"w2v_features\", \"tags_features\", \"title_len\", \"body_len\", \"punct_count\", \"avg_word_len\"],\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    (train_data, test_data) = df_featured.randomSplit([0.8, 0.2], seed=42)\n",
    "    train_data.cache(); test_data.cache()\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "    lr_pipeline = Pipeline(stages=[\n",
    "        label_indexer, tokenizer, stopwords_remover, ngram, \n",
    "        w2v, hashing_tf_tags, idf_tags, \n",
    "        feature_assembler, lr\n",
    "    ])\n",
    "    \n",
    "    lr_model = lr_pipeline.fit(train_data)\n",
    "    lr_predictions = lr_model.transform(test_data)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    accuracy = evaluator.setMetricName(\"accuracy\").evaluate(lr_predictions)\n",
    "    f1_score = evaluator.setMetricName(\"f1\").evaluate(lr_predictions)\n",
    "    \n",
    "    print(\"\\nlog reg results:\")\n",
    "    print(f\"accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 score: {f1_score:.4f}\")\n",
    "    print(\"conf m:\")\n",
    "    lr_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "\n",
    "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "    rf_pipeline = Pipeline(stages=[\n",
    "        label_indexer, tokenizer, stopwords_remover, ngram, \n",
    "        w2v, hashing_tf_tags, idf_tags, \n",
    "        feature_assembler, rf\n",
    "    ])\n",
    "\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf.numTrees, [50, 100]) \\\n",
    "        .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "        .build()\n",
    "\n",
    "    crossval = CrossValidator(estimator=rf_pipeline, \n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"),\n",
    "                              numFolds=3) \n",
    "    \n",
    "    print(\"\\nRF HP optimization:\")\n",
    "    cv_model = crossval.fit(train_data)\n",
    "    best_rf_model = cv_model.bestModel\n",
    "    rf_predictions = best_rf_model.transform(test_data)\n",
    "    \n",
    "    accuracy = evaluator.setMetricName(\"accuracy\").evaluate(rf_predictions)\n",
    "    f1_score = evaluator.setMetricName(\"f1\").evaluate(rf_predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    best_params = best_rf_model.stages[-1]\n",
    "    print(f\"best params: numTrees={best_params.numTrees}, maxDepth={best_params.maxDepth}\")\n",
    "    \n",
    "    print(\"conf m:\")\n",
    "    rf_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n",
    "\n",
    "except Exception as e: traceback.print_exc()\n",
    "finally: spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0e985",
   "metadata": {},
   "source": [
    "# todo  word2vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"w2v_features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
